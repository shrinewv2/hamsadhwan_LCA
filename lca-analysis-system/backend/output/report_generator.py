"""Output 1 — Markdown Report Generator."""

from datetime import datetime, timezone
from typing import Any

import structlog

from backend.storage.s3_client import upload_text

logger = structlog.get_logger(__name__)


async def generate_report(
    job_id: str,
    synthesis_result: dict[str, Any],
    validation_summaries: list[dict[str, Any]] | None = None,
    file_records: list[dict[str, Any]] | None = None,
) -> str:
    """Assemble the full Markdown report from synthesis outputs.

    Structure:
    1. Title section with job metadata
    2. Stage 2: Cross-document synthesis
    3. Stage 3: Insights (hotspots, consolidated table, uncertainty, completeness, recommendations)
    4. Per-document summaries (Stage 1) as appendix
    5. Validation results summary table
    6. Metadata footer
    """
    now = datetime.now(timezone.utc).strftime("%Y-%m-%d %H:%M UTC")
    file_records = file_records or []
    validation_summaries = validation_summaries or []

    parts: list[str] = []

    # ─── 1. Title Section ───
    parts.append(f"# LCA Analysis Report\n")
    parts.append(f"**Job ID:** `{job_id}`  ")
    parts.append(f"**Date:** {now}  ")
    parts.append(f"**Files Processed:** {len(file_records)}\n")

    if file_records:
        parts.append("| # | Filename | Type | Agent | Confidence | Status |")
        parts.append("|---|----------|------|-------|------------|--------|")
        for i, fr in enumerate(file_records, 1):
            parts.append(
                f"| {i} | {fr.get('original_name', 'N/A')} | "
                f"{fr.get('file_type', 'N/A')} | {fr.get('agent', 'N/A')} | "
                f"{fr.get('confidence', 0):.2f} | {fr.get('status', 'N/A')} |"
            )
        parts.append("")

    parts.append("---\n")

    # ─── 2. Cross-Document Synthesis ───
    cross_doc = synthesis_result.get("cross_doc_synthesis", "")
    if cross_doc:
        parts.append(cross_doc)
        parts.append("\n---\n")

    # ─── 3. Insights ───
    insights = synthesis_result.get("insights_markdown", "")
    if insights:
        parts.append(insights)
        parts.append("\n---\n")

    # ─── 4. Per-Document Summaries (Appendix) ───
    doc_summaries = synthesis_result.get("doc_summaries", [])
    if doc_summaries:
        parts.append("# Appendix: Per-Document Summaries\n")
        for i, ds in enumerate(doc_summaries, 1):
            parts.append(f"## Document {i}: {ds.get('filename', 'Unknown')}\n")
            parts.append(f"**Type:** {ds.get('file_type', 'N/A')} | "
                         f"**Agent:** {ds.get('agent', 'N/A')} | "
                         f"**Confidence:** {ds.get('confidence', 0):.2f}\n")
            parts.append(ds.get("summary", "*No summary available.*"))
            parts.append("\n---\n")

    # ─── 5. Validation Results Table ───
    if validation_summaries:
        parts.append("# Validation Results\n")
        parts.append("| File | Status | Rule Errors | Rule Warnings | Taxonomy Issues | Data Quality |")
        parts.append("|------|--------|-------------|---------------|-----------------|--------------|")
        for vs in validation_summaries:
            parts.append(
                f"| {vs.get('filename', 'N/A')} | {vs.get('status', 'N/A')} | "
                f"{len(vs.get('rule_errors', []))} | {len(vs.get('rule_warnings', []))} | "
                f"{len(vs.get('taxonomy_issues', []))} | {vs.get('data_quality_rating', 'N/A')} |"
            )
        parts.append("")

    # ─── 6. Metadata Footer ───
    parts.append("---\n")
    parts.append(f"*Report generated by LCA Multi-Agent Analysis System on {now}*  ")
    parts.append(f"*Job ID: {job_id}*")

    report = "\n".join(parts)

    # Store to S3
    s3_key = f"reports/{job_id}/full_report.md"
    try:
        await upload_text(s3_key, report, content_type="text/markdown")
        logger.info("report_uploaded_to_s3", job_id=job_id, s3_key=s3_key, length=len(report))
    except Exception as e:
        logger.error("report_s3_upload_failed", job_id=job_id, error=str(e))

    return report
